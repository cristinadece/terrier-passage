{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load utils and store variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Loading list of clustersb- from k=2 to 11  for 194 queries!!!\n",
    "%store -r resultDictList\n",
    "print(len(resultDictList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46656\n"
     ]
    }
   ],
   "source": [
    "# Load all combi\n",
    "%store -r all_combi\n",
    "print(len(all_combi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read all files with results - one per query\n",
    "def loadQidBM25P(dirPath):\n",
    "    os.chdir(dirPath)\n",
    "    qidDict = dict()\n",
    "    for filename in os.listdir(os.curdir):\n",
    "        if filename.startswith(\"trec-eval-all-weights-qid-\"):\n",
    "            queryID = int(filename.split(\".\")[0].split(\"-\")[-1])\n",
    "            with open(filename) as f:\n",
    "                weights2metrics = dict()\n",
    "                for line in f:\n",
    "                    if len(line.split(\"\\t\"))==2:\n",
    "                        weight_combo, metrics = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "                        weights2metrics[weight_combo] = metrics\n",
    "                    else:\n",
    "                        print(line)\n",
    "            qidDict[queryID] = weights2metrics\n",
    "    return qidDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qidDict = loadQidBM25P(\"/home/muntean/terrier-passage/tfs-per-qid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "dict_keys([25, 103, 171, 15, 177, 18, 112, 62, 37, 198, 134, 68, 163, 193, 138, 29, 34, 164, 78, 128, 8, 89, 92, 61, 95, 197, 195, 153, 35, 140, 85, 57, 101, 47, 176, 5, 139, 31, 65, 99, 48, 50, 53, 82, 26, 90, 94, 187, 51, 137, 69, 148, 58, 106, 175, 91, 143, 196, 28, 86, 49, 2, 16, 64, 127, 132, 93, 54, 100, 125, 133, 179, 141, 189, 80, 130, 3, 191, 178, 17, 24, 122, 116, 39, 87, 20, 158, 46, 126, 108, 23, 167, 6, 73, 129, 102, 149, 14, 27, 88, 190, 155, 63, 160, 194, 135, 124, 71, 36, 168, 12, 174, 156, 119, 97, 19, 21, 180, 67, 104, 59, 43, 1, 84, 200, 184, 186, 146, 98, 52, 185, 13, 131, 60, 152, 162, 120, 118, 166, 42, 157, 154, 161, 105, 74, 199, 4, 7, 182, 165, 72, 70, 83, 30, 151, 145, 96, 77, 79, 40, 142, 45, 111, 38, 172, 150, 114, 76, 144, 170, 55, 136, 66, 32, 10, 115, 181, 173, 169, 9, 11, 123, 192, 44, 75, 109, 107, 159, 41, 117, 121, 56, 22, 33, 110, 81, 113, 183, 147, 188])\n"
     ]
    }
   ],
   "source": [
    "print(len(qidDict))\n",
    "print(qidDict.keys())\n",
    "# print(len(qidDict[71]))\n",
    "# print(qidDict[71][\"111111\"])\n",
    "# print(qidDict[71][\"111345\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group queries intro cluster and select trec_eval metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMetricPerQuery(weights2metrics, metric=\"recall_1000\"):\n",
    "    metricDict = dict()\n",
    "    metricList = list()\n",
    "    for weight, metric_str in weights2metrics.items():\n",
    "        all_metrics = metric_str.split(\",\")\n",
    "        for m in all_metrics:\n",
    "            if m.startswith(metric):\n",
    "                metricDict[int(weight)] = float(m.split(\":\")[2])\n",
    "    return metricDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getClusterTable(resultDict, qidDict):\n",
    "    cluster2table = defaultdict(list)\n",
    "    for cluster, queries in resultDict.items():\n",
    "        for qid, metric_str in qidDict.items():\n",
    "            if qid in queries:\n",
    "                dictQ = getMetricPerQuery(qidDict[qid], \"recall_1000\")\n",
    "                cluster2table[cluster].append(dictQ)  \n",
    "    return cluster2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(len(cluster2table))\n",
    "# print(cluster2table.keys())\n",
    "# print(len(cluster2table[1]))\n",
    "# print(cluster2table[1][1].keys())\n",
    "# print(len(cluster2table[1][1].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster2tableK2 = getClusterTable(resultDictList[0], qidDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster2tableK3 = getClusterTable(resultDictList[1], qidDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDictK4 = copy.deepcopy(resultDictList[2])\n",
    "del resultDictK4[3]\n",
    "resultDictK4[1].append(150)\n",
    "\n",
    "cluster2tableK4 = getClusterTable(resultDictK4, qidDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDictK5 = copy.deepcopy(resultDictList[3])\n",
    "del resultDictK5[3]\n",
    "resultDictK5[1].append(150)\n",
    "\n",
    "cluster2tableK5 = getClusterTable(resultDictK5, qidDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultListAltered = [resultDictList[0], resultDictList[1], resultDictK4, resultDictK5 ]\n",
    "%store resultListAltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster2best = defaultdict(list)\n",
    "cluster2classic = defaultdict(list)\n",
    "weightdictCluster = dict()\n",
    "weightdictCluster[0] = 211112\n",
    "weightdictCluster[1] = 211213\n",
    "for cluster, queries in resultDictList[0].items():\n",
    "    for qid, metric_str in qidDict.items():\n",
    "        if qid in queries:\n",
    "            dictQ = getMetricPerQuery(qidDict[qid], \"recall_1000\")\n",
    "            cluster2best[cluster].append(dictQ[weightdictCluster[cluster]])  \n",
    "            cluster2classic[cluster].append(dictQ[111111]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster2best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-57e01f2caae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# WE NEED AT LEAST 5 % DIFFENRENCE FOR 179 QUERIES!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster2best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster2best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster2best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster2classic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster2classic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster2classic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster2best' is not defined"
     ]
    }
   ],
   "source": [
    "# print(cluster2best)\n",
    "# print(cluster2classic)\n",
    "\n",
    "\n",
    "# FOR K=2 ANY DIFFERENCE IS NOT STATISTICALLY SIGNIFICANT\n",
    "# WE NEED AT LEAST 5 % DIFFENRENCE FOR 179 QUERIES!\n",
    "\n",
    "print(np.mean(cluster2best[0]), np.std(cluster2best[0]), len(cluster2best[0]))\n",
    "print(np.mean(cluster2classic[0]), np.std(cluster2classic[0]), len(cluster2classic[0]))\n",
    "print()\n",
    "print(np.mean(cluster2best[1]), np.std(cluster2best[1]), len(cluster2best[1]))\n",
    "print(np.mean(cluster2classic[1]), np.std(cluster2classic[1]), len(cluster2classic[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate results per cluster and get Dataframe after filtering weights bigger or equal than 111111 - Classic BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dsum(dict_list):\n",
    "    ret = defaultdict(float)\n",
    "    denominator = len(dict_list)\n",
    "    for d in dict_list:\n",
    "        for k, v in d.items():\n",
    "            ret[k] += v/denominator\n",
    "    return dict(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDF(cluster_dict, biggerThan=111111):\n",
    "    a = sorted(cluster_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    df = pd.DataFrame(a, columns=['Weighting', 'Metric'])\n",
    "    if biggerThan is not None:\n",
    "        u = float(df.loc[df['Weighting'] == biggerThan][\"Metric\"])\n",
    "        return df.loc[df[\"Metric\"] >= u]\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCluster2df(cluster2table):\n",
    "    cluster2df = dict()\n",
    "    cluster2df_all = dict()\n",
    "    index = range(len(all_combi))\n",
    "    for k,v in cluster2table.items():\n",
    "        cluster_dict = dsum(v)\n",
    "        cluster2df[k] = getDF(cluster_dict)  \n",
    "        cluster2df_all[k] = getDF(cluster_dict, None)\n",
    "    return cluster2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cluster2dfK2 = getCluster2df(cluster2tableK2)\n",
    "# cluster2dfK3 = getCluster2df(cluster2tableK3)\n",
    "# cluster2dfK4 = getCluster2df(cluster2tableK4)\n",
    "cluster2dfK5 = getCluster2df(cluster2tableK5)\n",
    "\n",
    "# %store cluster2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store cluster2dfK2\n",
    "# %store cluster2dfK2\n",
    "# %store cluster2dfK4\n",
    "# %store cluster2dfK5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "averageBest = 0\n",
    "averageClassic = 0\n",
    "cluster2weight = dict()\n",
    "cluster2classic = dict()\n",
    "\n",
    "for cluster, df in cluster2dfK5.items():\n",
    "    print(\"Cluster:\" , cluster)\n",
    "    print()\n",
    "    print(\"Max BM25P value\", df.head(1))\n",
    "    print()\n",
    "    print(\"B25 classic\", df.loc[df['Weighting'] == 111111])\n",
    "    print()\n",
    "    print(\"Number of BM25P bigger than baseline: \", len(df.index))\n",
    "    print(\"---------------------------\")\n",
    "    print()\n",
    "    averageBest += float(df.head(1)['Metric'])\n",
    "    averageClassic += float(df.loc[df['Weighting'] == 111111]['Metric'])\n",
    "    cluster2weight[cluster] = (int(df.head(1)['Weighting']),float(df.head(1)['Metric']))\n",
    "    cluster2classic[cluster] = (111111,float(df.loc[df['Weighting'] == 111111]['Metric']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average BM25P Best on all clusters: \",averageBest/len(cluster2dfK5))\n",
    "print(\"Average BM25P Classic on all clusters: \",averageClassic/len(cluster2dfK5))\n",
    "print()\n",
    "print(cluster2weight)\n",
    "print()\n",
    "print(cluster2classic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## See progression with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotWeightInc(best_w, df):\n",
    "    values = []\n",
    "    labels = []\n",
    "    for i in range(1,7):\n",
    "        current_w = best_w[:i] + \"1\"*(6-i)\n",
    "        labels.append(current_w)\n",
    "        values.append(float(df.loc[df['Weighting'] == int(current_w)]['Metric']) - float(df.loc[df['Weighting'] == int(\"111111\")]['Metric']))\n",
    "    labels.append(best_w)\n",
    "    \n",
    "    print(values)\n",
    "    print(labels)\n",
    "    plt.figure()\n",
    "    plt.plot(values, \"o-\")\n",
    "    for i, val in enumerate(values):\n",
    "        plt.annotate(str(val), (i,val))\n",
    "    plt.xticks(range(6), labels)\n",
    "    plt.title(best_w)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster, df in cluster2df_all.items():\n",
    "    best_w = str(cluster2weight[cluster][0])\n",
    "    plotWeightInc(best_w, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select random weight from the available values! \n",
    "\n",
    "best_weights = [x for x,y  in cluster2weight.values()]\n",
    "print(best_weights)\n",
    "best_weights = [111111 if x==0 else x for x in best_weights]\n",
    "print(best_weights)\n",
    "\n",
    "random_mean_100 = 0\n",
    "for i in range(100):\n",
    "    vals = list()\n",
    "    for cluster, df in cluster2df_all.items():\n",
    "        weight = np.random.choice(best_weights)\n",
    "        vals.append(float(df.loc[df['Weighting'] == int(weight)]['Metric']))\n",
    "        #print(cluster, weight, float(df.loc[df['Weighting'] == int(weight)]['Metric']))\n",
    "    random_mean_100 += np.mean(vals)\n",
    "print()\n",
    "print(\"Average BM25P Random on all clusters: \", random_mean_100/100)\n",
    "print(\"Average BM25P Best on all clusters: \",averageBest/len(cluster2df))\n",
    "print(\"Average BM25P Classic on all clusters: \",averageClassic/len(cluster2df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
