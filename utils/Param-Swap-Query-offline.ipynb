{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import gzip\n",
    "import io\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesian product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_combi = list(itertools.product(range(6), repeat=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46656\n",
      "(2, 3, 2, 3, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "print len(all_combi)\n",
    "print all_combi[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(N, df):\n",
    "    return math.log((N - df + 0.5) / (df + 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_tf_with_postings(weights, positions, doc_len):\n",
    "    steps = [0,100,200,400,600,1000]\n",
    "    tfs = np.zeros(6)\n",
    "    for pos in positions:\n",
    "        for step_i, step_j in pairwise(steps):\n",
    "            if pos >= step_i and pos < step_j:\n",
    "                tfs[steps.index(step_i)] += 1\n",
    "        if pos > steps[-1]:\n",
    "            tfs[-1] += 1\n",
    "    print tfs\n",
    "    return sum([a*b for a,b in zip(weights,tfs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_tf(weights, tfs):\n",
    "    return sum([a*b for a,b in zip(weights,tfs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm25(tf, df, doclen, N, avg_doclen, k1=1.2, b=0.75):\n",
    "    return idf(N, df) * ((tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doclen / avg_doclen))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## From Terrier\n",
    "# double K = this.k_1 * (1.0D - this.b + this.b * docLength / this.averageDocumentLength);\n",
    "# return WeightingModelLibrary.log((this.numberOfDocuments - this.documentFrequency + 0.5D)\n",
    "#         / (this.documentFrequency + 0.5D)) * ((this.k_1 + 1.0D) * tf / (K + tf)) *\n",
    "#         ((this.k_3 + 1.0D) * this.keyFrequency / (this.k_3 + this.keyFrequency));\n",
    "\n",
    "def bm25Terrier(tf, df, doclen, N, avg_doclen, k1=1.2, k3=8, b=0.75):\n",
    "    K = k1 * (1.0 - b + b * doclen / avg_doclen)\n",
    "    bm25 = math.log((N - df + 0.5) / (df + 0.5)) * ((k1 + 1.0) * tf / (K + tf)) * ((k3 + 1.0) * 1 / (k3 + 1)) \n",
    "    return bm25\n",
    "\n",
    "#bm25terrier = bm25Terrier(new_tf, df_list[i], doclen, N, AVG_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file with info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 query - all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1513614203.21\n",
      "Finished,  2.06184005737\n"
     ]
    }
   ],
   "source": [
    "# Read doc txt: TAB separated\n",
    "# qid,\n",
    "# N,\n",
    "# Arrays.toString(documentFrequencies),\n",
    "# avgDocLen,\n",
    "# docid,\n",
    "# docno,\n",
    "# doclen,\n",
    "# tf_q1, tf_q2, tf_q3, tf_q4, tf_q5, tf_q6\n",
    "\n",
    "i = 0 \n",
    "N = 50220423\n",
    "AVG_LEN = 963.90334\n",
    "\n",
    "docid2docno = dict()\n",
    "docid2weightbm25 = dict()\n",
    "\n",
    "start = time.time()\n",
    "print \"Starting\", start\n",
    "with io.BufferedReader(gzip.open(\"/home/muntean/terrier-passage/tfs-per-qid/all-matches-fields-tfs-qid-159.txt.gz\", \"rb\")) as inputFile:\n",
    "    for line in inputFile:\n",
    "#         print line\n",
    "        i += 1\n",
    "        if i%10000 == 0:\n",
    "            print \"Processed \", i*10000, \" documents\"\n",
    "        data = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        qid = int(data[0])\n",
    "        df_list = json.loads(data[2])\n",
    "        docid = int(data[4])\n",
    "        docno = data[5]\n",
    "        doclen = int(data[6])\n",
    "        tf_list = np.array(json.loads(data[7]))\n",
    "        \n",
    "        \n",
    "        weight2bm25 = defaultdict(float)\n",
    "        \n",
    "        a = time.time()\n",
    "        \n",
    "        for combo in all_combi:\n",
    "#             print combo\n",
    "            doc_bm25 = 0\n",
    "            for i, term_tf_list in enumerate(tf_list):  \n",
    "                new_tf = weighted_tf(combo, term_tf_list)\n",
    "                bm25classic =  bm25(new_tf, df_list[i], doclen, N, AVG_LEN)\n",
    "                doc_bm25 += bm25classic\n",
    "            weight2bm25[combo] = doc_bm25\n",
    "        \n",
    "        docid2docno[docid] = docno\n",
    "        docid2weightbm25[docid] = weight2bm25\n",
    "#         print weight2bm25\n",
    "#         print\n",
    "#         print docid2weightbm25.keys()\n",
    "        \n",
    "#         print time.time() - a\n",
    "#         break\n",
    "print \"Finished, \", (time.time() - start) #/ 3600\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All documents - 1 combination - on the biggest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read doc txt: TAB separated\n",
    "# qid,\n",
    "# N,\n",
    "# Arrays.toString(documentFrequencies),\n",
    "# avgDocLen,\n",
    "# docid,\n",
    "# docno,\n",
    "# doclen,\n",
    "# tf_q1, tf_q2, tf_q3, tf_q4, tf_q5, tf_q6\n",
    "\n",
    "def alldocs1combo(qid):\n",
    "\n",
    "    i = 0 \n",
    "    N = 50220423\n",
    "    AVG_LEN = 963.90334\n",
    "\n",
    "    docid2docno = dict()\n",
    "    docid2weightbm25 = dict()\n",
    "\n",
    "    start = time.time()\n",
    "    print \"Starting\", start\n",
    "    with io.BufferedReader(gzip.open(\"/home/muntean/terrier-passage/tfs-per-qid/all-matches-fields-tfs-qid-\"+str(qid)+\".txt.gz\", \"rb\")) as inputFile:\n",
    "        for line in inputFile:\n",
    "    #         print line\n",
    "            i += 1\n",
    "#             if i%10000==0:\n",
    "#                 print \"Processed \", i, \" documents\"\n",
    "            data = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "            qid = int(data[0])\n",
    "            df_list = json.loads(data[2])\n",
    "            docid = int(data[4])\n",
    "            docno = data[5]\n",
    "            doclen = int(data[6])\n",
    "            tf_list = np.array(json.loads(data[7]))\n",
    "\n",
    "\n",
    "            weight2bm25 = defaultdict(float)\n",
    "\n",
    "            a = time.time()\n",
    "\n",
    "\n",
    "            doc_bm25 = 0\n",
    "            for i, term_tf_list in enumerate(tf_list):\n",
    "    #             print combo[20000]\n",
    "    #             print term_tf_list\n",
    "                new_tf = weighted_tf(all_combi[20000], term_tf_list)\n",
    "                bm25classic =  bm25(new_tf, df_list[i], doclen, N, AVG_LEN)\n",
    "                doc_bm25 += bm25classic\n",
    "            weight2bm25[combo] = doc_bm25\n",
    "\n",
    "            docid2docno[docid] = docno\n",
    "            docid2weightbm25[docid] = weight2bm25\n",
    "    #         print weight2bm25\n",
    "    #         print\n",
    "    #         print docid2weightbm25.keys()\n",
    "\n",
    "    #         print time.time() - a\n",
    "\n",
    "    print \"Finished, \", (time.time() - start) #/ 3600\n",
    "    print len(docid2docno)\n",
    "    print len(docid2weightbm25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the biggest file q: 66\n",
    "\n",
    "Starting 1513589752.1\n",
    "\n",
    "Finished,  3193.33556914"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only reading time\n",
    "\n",
    "Starting 1513601966.22\n",
    "\n",
    "Finished,  730.704658031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1513601966.22\n",
      "Finished,  730.704658031\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "alldocs1combo(66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1513593846.79\n",
      "Finished,  549.572243929\n",
      "4547350\n",
      "4547350\n"
     ]
    }
   ],
   "source": [
    "# q:2, file: 52M, docs: 4.547.353 \n",
    "\n",
    "alldocs1combo(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1513594475.38\n",
      "Finished,  0.405613183975\n",
      "7425\n",
      "7425\n"
     ]
    }
   ],
   "source": [
    "# q: 90, file: 93k, docs: 7.425\n",
    "\n",
    "alldocs1combo(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1513594574.81\n",
      "Finished,  0.140665054321\n",
      "2621\n",
      "2621\n"
     ]
    }
   ],
   "source": [
    "# q: 168, file: 36k, docs: 2.621\n",
    "\n",
    "alldocs1combo(168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
