{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the .res file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "from scipy import sparse\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import progress_bar\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from sys import getsizeof\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %store -r dataset\n",
    "# dataset.shape[0]\n",
    "\n",
    "dataset = pd.read_json(\"signalmedia-1m.jsonl\", lines=True)\n",
    "dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getsizeof(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryTitleDoc = defaultdict()\n",
    "for i in progress_bar.iter_progress(range(dataset.shape[0])):\n",
    "    docid = dataset[\"id\"].iloc[i]\n",
    "    queryTitleDoc[int(i)] = docid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(queryTitleDoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('queryTitleDoc.json', 'w') as fp:\n",
    "    json.dump(queryTitleDoc, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('queryTitleDoc.json') as json_data:\n",
    "    qTitleD = json.load(json_data)\n",
    "    print(len(qTitleD))\n",
    "    print(qTitleD[\"2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query classes\n",
    "1. We consider news headlines/title as queries, with a single relevant results, the corresponding article.\n",
    "2. We perform ranking on the (whole) collection, and we can have the following scenarios:\n",
    "\n",
    "    a) R@1 = 1, i.e., the top document retrieved is the correct one\n",
    "    \n",
    "    b) R@1 != 1 but R@10 = 1, i.e., the correct document is not the first, but among the first 10\n",
    "    \n",
    "    c) else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from Terrier BM25 have this shape\n",
    "    0 Q0 f7ca322d-c3e8-40d2-841f-9d7250ac72ca 0 67.80570840241509 BM25b0.75\n",
    "    0 Q0 5ed3ed90-b025-4f90-98ab-48ac1182f3a7 1 33.68442635555825 BM25b0.75\n",
    "    0 Q0 80cade5d-dfbb-4887-8700-34032ed708d9 2 33.14615405559586 BM25b0.75\n",
    "    0 Q0 84947a2e-31ea-41a6-a63c-ba2b4bde2caa 3 31.083372155166458 BM25b0.75\n",
    "    0 Q0 d1521e9f-ca2c-4ca0-9179-4966d508ebc2 4 30.724469746013728 BM25b0.75\n",
    "    0 Q0 ddcda110-461f-4608-8509-b4080e80c305 5 30.02468908628416 BM25b0.75\n",
    "    0 Q0 17e25f0c-7afe-480d-a270-2b477c0033e6 6 29.665149620555425 BM25b0.75\n",
    "    0 Q0 9752f0cf-61ae-46ee-8494-6edb03b7d24d 7 29.66147722262594 BM25b0.75\n",
    "    0 Q0 df87f8ee-9904-4f67-9590-5d0fa2cd2adb 8 29.460120040217348 BM25b0.75\n",
    "    0 Q0 1738286d-9853-4b53-aab1-f418835ac1e3 9 29.444973786956144 BM25b0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryType = defaultdict(list) # the key is A, B or C and the values are list of queryId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0 \n",
    "\n",
    "with open(\"BM25-signal.res\", \"r\") as f:\n",
    "    for line in progress_bar.iter_progress(f):\n",
    "        i+=1\n",
    "        if i % 10000 ==0 :\n",
    "            print(\"Processed: \", i)\n",
    "        resultLine = line.split()\n",
    "        queryId = int(resultLine[0])\n",
    "        if not int(resultLine[3]) > 100: \n",
    "            if int(resultLine[3]) == 0:  # class A\n",
    "                if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                    queryType[\"A\"].append(queryId)\n",
    "                    continue\n",
    "            elif int(resultLine[3]) < 10: # class B\n",
    "                if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                    queryType[\"B\"].append(queryId)\n",
    "                    continue\n",
    "            elif int(resultLine[3]) < 100: # class C\n",
    "                 if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                    queryType[\"C\"].append(queryId)\n",
    "                    continue\n",
    "        else:\n",
    "            if resultLine[2] == queryTitleDoc[queryId]:                \n",
    "                queryType[\"D\"].append(queryId)\n",
    "#                 print(line)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for qType, qList in queryType.items():\n",
    "    print(qType, len(qList), len(set(qList)))\n",
    "    \n",
    "print(i)\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all = set(range(1459))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(all - set(queryType[\"A\"]) - set(queryType[\"B\"]) - set(queryType[\"C\"]) - set(queryType[\"D\"]))\n",
    "# these are queries which don't have the CORRECT Doc retrieved at all... e.g. query 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryTitleDoc[206] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.iloc[206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset[\"content\"].iloc[206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.iloc[206][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Query types on Terrier\n",
    "\n",
    "* ('A', 390058)\n",
    "* ('C', 131121)\n",
    "* ('B', 302560)\n",
    "* ('D', 64843)\n",
    "* No docs in top 1000 results: 111418\n",
    "\n",
    "Put of a total of 1.000.000 we have the 4 types of queries summing up to 888582. \n",
    "\n",
    "All the other queries don't have the CORRECT doc in the retrieved results. See example above: article 206\n",
    "\n",
    "\n",
    "```\n",
    "            if not int(resultLine[3]) > 1000:\n",
    "                if int(resultLine[3]) == 0:  # class A\n",
    "                    if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                        queryType[\"A\"].append(queryId)\n",
    "                        continue\n",
    "                elif int(resultLine[3]) < 10: # class B\n",
    "                    if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                        queryType[\"B\"].append(queryId)\n",
    "                        continue\n",
    "                elif int(resultLine[3]) < 100: # class C\n",
    "                    if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                        queryType[\"C\"].append(queryId)\n",
    "                        continue\n",
    "                elif int(resultLine[3]) < 1000: # class C\n",
    "                    if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                        queryType[\"D\"].append(queryId)\n",
    "            else:\n",
    "                if resultLine[2] == queryTitleDoc[queryId]:\n",
    "                    queryType[\"E\"].append(queryId)\n",
    "                    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('queryTypeTerrier.json') as json_data:\n",
    "    qTypeTerrier = json.load(json_data)\n",
    "    print(len(qTypeTerrier))\n",
    "    print(len(qTypeTerrier[\"A\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query types on Elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "They come from 5 files each with 200.000 queries (we split the 1 mil for speedier processing)\n",
    "\n",
    "0-200.000\n",
    "('A', 83481)\n",
    "('C', 24437)\n",
    "('B', 58630)\n",
    "('D', 11651)\n",
    "\n",
    "200-400\n",
    "('A', 82510)\n",
    "('C', 24669)\n",
    "('B', 59408)\n",
    "('D', 11743)\n",
    "\n",
    "400-600\n",
    "('A', 82569)\n",
    "('C', 24853)\n",
    "('B', 59332)\n",
    "('D', 11668)\n",
    "\n",
    "600-800\n",
    "('A', 81463)\n",
    "('C', 25049)\n",
    "('B', 59921)\n",
    "('D', 11734)\n",
    "\n",
    "800-1000\n",
    "('A', 81103)\n",
    "('C', 25225)\n",
    "('B', 60310)\n",
    "('D', 11628)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('queryTypeElastic200.json') as json_data:\n",
    "    qTypeElastic200 = json.load(json_data)\n",
    "    print(len(qTypeElastic200))\n",
    "    print(len(qTypeElastic200[\"A\"]))\n",
    "    \n",
    "with open('queryTypeElastic400.json') as json_data:\n",
    "    qTypeElastic400 = json.load(json_data)\n",
    "    print(len(qTypeElastic400))\n",
    "    print(len(qTypeElastic400[\"A\"]))\n",
    "    \n",
    "with open('queryTypeElastic600.json') as json_data:\n",
    "    qTypeElastic600 = json.load(json_data)\n",
    "    print(len(qTypeElastic600))\n",
    "    print(len(qTypeElastic600[\"A\"]))\n",
    "\n",
    "with open('queryTypeElastic800.json') as json_data:\n",
    "    qTypeElastic800 = json.load(json_data)\n",
    "    print(len(qTypeElastic800))\n",
    "    print(len(qTypeElastic800[\"A\"]))\n",
    "    \n",
    "with open('queryTypeElastic1000.json') as json_data:\n",
    "    qTypeElastic1000 = json.load(json_data)\n",
    "    print(len(qTypeElastic1000))\n",
    "    print(len(qTypeElastic1000[\"A\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's try some intersections and make sure they are null\n",
    "print(len(set(qTypeElastic200[\"A\"]).intersection(set(qTypeElastic1000[\"D\"]))))\n",
    "\n",
    "# we shall unite!\n",
    "print(len(set(qTypeElastic200[\"A\"]))+len(set(qTypeElastic400[\"A\"])))\n",
    "print(len(set(qTypeElastic200[\"A\"]).union(set(qTypeElastic400[\"A\"]))))\n",
    "\n",
    "qTypeElastic = defaultdict()\n",
    "qTypeElastic[\"A\"] = set(qTypeElastic200[\"A\"]) | set(qTypeElastic400[\"A\"]) | set(qTypeElastic600[\"A\"]) | set(qTypeElastic800[\"A\"]) | set(qTypeElastic1000[\"A\"])\n",
    "qTypeElastic[\"B\"] = set(qTypeElastic200[\"B\"]) | set(qTypeElastic400[\"B\"]) | set(qTypeElastic600[\"B\"]) | set(qTypeElastic800[\"B\"]) | set(qTypeElastic1000[\"B\"])\n",
    "qTypeElastic[\"C\"] = set(qTypeElastic200[\"C\"]) | set(qTypeElastic400[\"C\"]) | set(qTypeElastic600[\"C\"]) | set(qTypeElastic800[\"C\"]) | set(qTypeElastic1000[\"C\"])\n",
    "qTypeElastic[\"D\"] = set(qTypeElastic200[\"D\"]) | set(qTypeElastic400[\"D\"]) | set(qTypeElastic600[\"D\"]) | set(qTypeElastic800[\"D\"]) | set(qTypeElastic1000[\"D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(qTypeElastic))\n",
    "for key, itemlist in qTypeElastic.items():\n",
    "    qTypeElastic[key] = sorted(list(itemlist))\n",
    "    print(key, len(itemlist))\n",
    "# the numbers are ok\n",
    "\n",
    "# dumping to file\n",
    "with open('queryTypeElastic.json', 'w') as fp:\n",
    "    json.dump(qTypeElastic, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(qTypeElastic[\"A\"]))\n",
    "print(qTypeElastic[\"A\"][:10])\n",
    "print(qTypeTerrier[\"A\"][:10])\n",
    "print(len(qTypeElastic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We intersect the 2 SE\n",
    "\n",
    "- we intersect A,B,C,D and decide upon the final queries\n",
    "- we run there queries on BM25P10 - idf and tfidf and count:\n",
    "    - how many intersect in A\n",
    "    - how many moved from B to A\n",
    "    - how many move from C to A and B and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's do some intersections\n",
    "queryTypeGlobal = defaultdict()\n",
    "for keyT, itemlistT in qTypeTerrier.items():\n",
    "    itemlistE = qTypeElastic[keyT]\n",
    "    itemlistG = sorted(list(set(itemlistT) & set(itemlistE)))\n",
    "    print(keyT)\n",
    "    print(\"Terrier: \", len(itemlistT), \" Elastic: \", len(itemlistE), \" Global: \",len(itemlistG))\n",
    "    queryTypeGlobal[keyT] = itemlistG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save global\n",
    "with open('queryTypeGlobal.json', 'w') as fp:\n",
    "    json.dump(queryTypeGlobal, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sample queries and qid:title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('queryTypeGlobal.json') as json_data:\n",
    "    qTypeGlobal = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 331954\n",
      "C 71573\n",
      "B 206440\n",
      "D 30420\n"
     ]
    }
   ],
   "source": [
    "for k,v in qTypeGlobal.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create random samples of queries and write them to file!\n",
    "\n",
    "for qType in [\"A\",\"B\",\"C\",\"D\"] :  \n",
    "    sample_10000 = random.sample(qTypeGlobal[qType], 15000)\n",
    "    with open(\"sample-15000-\"+ qType + \".txt\", 'w') as fp:\n",
    "        json.dump(sample_10000, fp) # we are writing a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "[628127, 975021, 897138, 737936, 605110, 765994, 162772, 792097, 161966, 294054, 433510, 997633, 928796, 556438, 242711, 686115, 690237, 385208, 280346, 392234]\n"
     ]
    }
   ],
   "source": [
    "with open('sample-15000-A.txt') as json_data:\n",
    "    sample10000A = json.load(json_data)\n",
    "    print(len(sample10000A))\n",
    "    print(sample10000A[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newTitle = dataset.title.str.replace('[^a-zA-Z ]', '')\n",
    "newTitle[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_sample_queries(newTitle, qtype):\n",
    "    sampleFilename = \"sample-15000-\"+ qtype + \".txt\"\n",
    "    with open(sampleFilename) as json_data:\n",
    "        sample_10000 = json.load(json_data)\n",
    "    with open(\"signal-title-queries-sample-15000-\"+ qtype + \".txt\", \"w\") as f:\n",
    "        for qid in sample_10000:\n",
    "            f.write(str(qid)+\":\"+newTitle[qid]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for qt in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    gen_sample_queries(newTitle, qt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Generate query groups according to HARDNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r signal_query_hardness_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333334 333333 333333\n",
      "[ 61653.              0.02506266] [ 697878.               0.05928854] [ 9237.    22.]\n",
      "[   234.    792.   1220. ...,  33639.  50879.  61653.]\n"
     ]
    }
   ],
   "source": [
    "query_hardness_list = list(signal_query_hardness_dict.items())\n",
    "sorted_query_hardness_list = sorted(query_hardness_list, key=lambda x: x[1])\n",
    "\n",
    "a,b,c = np.array_split(np.array(sorted_query_hardness_list),3)\n",
    "\n",
    "print(len(a),len(b), len(c))\n",
    "np.set_printoptions(suppress=True)\n",
    "print(a[-1], b[-1], c[-1])\n",
    "print(a[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333334 333333 333333\n"
     ]
    }
   ],
   "source": [
    "# We look at the intervals from above\n",
    "h = a[:,0].astype(int).tolist()\n",
    "m = b[:,0].astype(int).tolist()\n",
    "e = c[:,0].astype(int).tolist()\n",
    "\n",
    "print(len(h),len(m), len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "91172\n",
      "122949\n",
      "117833\n",
      "B\n",
      "69101\n",
      "81478\n",
      "55861\n",
      "C\n",
      "27708\n",
      "22935\n",
      "20930\n",
      "D\n",
      "13239\n",
      "6449\n",
      "10732\n"
     ]
    }
   ],
   "source": [
    "for qType in [\"A\",\"B\",\"C\",\"D\"] :\n",
    "    print(qType)\n",
    "    group_intersect_H = set(qTypeGlobal[qType]) & set(h)\n",
    "    group_intersect_M = set(qTypeGlobal[qType]) & set(m)\n",
    "    group_intersect_E = set(qTypeGlobal[qType]) & set(e)\n",
    "    \n",
    "    print(len(group_intersect_H))\n",
    "    print(len(group_intersect_M))\n",
    "    print(len(group_intersect_E))\n",
    "    \n",
    "    sample_H1000 = random.sample(group_intersect_H, 1000)\n",
    "    sample_M1000 = random.sample(group_intersect_M, 1000)\n",
    "    sample_E1000 = random.sample(group_intersect_E, 1000)\n",
    "\n",
    "    with open(\"sample-H1000-\"+ qType + \".txt\", 'w') as fp:\n",
    "        json.dump(sample_H1000, fp) # we are writing a list\n",
    "    with open(\"sample-M1000-\"+ qType + \".txt\", 'w') as fp:\n",
    "        json.dump(sample_M1000, fp) # we are writing a list\n",
    "    with open(\"sample-E1000-\"+ qType + \".txt\", 'w') as fp:\n",
    "        json.dump(sample_E1000, fp) # we are writing a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_sample_queries(newTitle, qtype, hardness):\n",
    "    sampleFilename = \"sample-\"+hardness+\"1000-\"+ qtype + \".txt\"\n",
    "    with open(sampleFilename) as json_data:\n",
    "        sample_10000 = json.load(json_data)\n",
    "    with open(\"signal-title-queries-sample-\"+hardness+\"1000-\"+ qtype + \".txt\", \"w\") as f:\n",
    "        for qid in sample_10000:\n",
    "            f.write(str(qid)+\":\"+newTitle[qid]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for qType in [\"A\",\"B\",\"C\",\"D\"] :\n",
    "    for hardness in [\"E\", \"M\", \"H\"]:\n",
    "        gen_sample_queries(newTitle, qType, hardness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
