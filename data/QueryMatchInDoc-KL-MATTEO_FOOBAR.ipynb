{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import os\n",
    "import xml.etree.ElementTree\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexOf(l, e, start=0):\n",
    "    for idx in range(start, len(l)):\n",
    "        if l[idx] is e:\n",
    "            return idx\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(N, df):\n",
    "    return math.log((N - df + 0.5) / (df + 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm25(tf, df, doclen, N, avg_doclen, k1=1.2, b=0.75):\n",
    "    return idf(N, df) * ((tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doclen / avg_doclen))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computePhraseFrequency(plists, window): \n",
    "            \n",
    "    MAX=float(\"+inf\")\n",
    "    MIN=float(\"-inf\")\n",
    "        \n",
    "    results=[]\n",
    "    for l in plists:\n",
    "        if len(l) < 1:\n",
    "            return results\n",
    "    \n",
    "    positions=plists \n",
    "    index = [0] * len(positions)\n",
    "    curr_occ = [0] * len (positions)\n",
    "    max_curr_occ = MIN\n",
    "    \n",
    "    for i in range(0, len(positions)):\n",
    "        curr_occ[i] = positions[i][0]\n",
    "        if curr_occ[i] > max_curr_occ:\n",
    "            max_curr_occ = curr_occ[i]\n",
    "    \n",
    "    lsym=0\n",
    "    rsym=0\n",
    "    lpos=0\n",
    "    while max_curr_occ < MAX:\n",
    "        _max = MIN\n",
    "        _min = MAX\n",
    "        for i in range(0, len(positions)):\n",
    "            if curr_occ[i] > _max:\n",
    "                _max = curr_occ[i]\n",
    "                rsym = i\n",
    "            if curr_occ[i] < _min:\n",
    "                _min = curr_occ[i]\n",
    "                lsym = i\n",
    "                \n",
    "        if index[lsym] == len(positions[lsym]) - 1 :\n",
    "            lpos = MAX\n",
    "        else :\n",
    "            index[lsym]+=1\n",
    "            lpos = positions[lsym][index[lsym]]\n",
    "        \n",
    "        if lpos > curr_occ[rsym] and curr_occ[rsym] - curr_occ[lsym] < window:\n",
    "                results.append(curr_occ[lsym])\n",
    "                \n",
    "        max_curr_occ = MAX\n",
    "        if lpos != MAX :\n",
    "            max_curr_occ = MIN\n",
    "            curr_occ[lsym] = lpos\n",
    "            for i in range(0, len(positions)):\n",
    "                if curr_occ[i] > max_curr_occ:\n",
    "                    max_curr_occ = curr_occ[i]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qid N dfs docid docno doclen avgdl rel positions\n",
    "def loadData():\n",
    "    qid2docs = defaultdict(list)    \n",
    "    i = 0 \n",
    "    with open(\"matteo_all.txt\") as f:\n",
    "        for l in f:\n",
    "            # split row\n",
    "            fields = l.split(\"\\t\")            \n",
    "            # get the data\n",
    "            qid = int(fields[0])\n",
    "            N = int(fields[1])\n",
    "            dfs = ast.literal_eval(fields[2])\n",
    "            docid = int(fields[3])\n",
    "            docno = fields[4]\n",
    "            doclen=int(fields[5])\n",
    "            avgdl=float(fields[6])\n",
    "            rel=int(fields[7])\n",
    "            plists = ast.literal_eval(fields[8])\n",
    "            \n",
    "            qid2docs[qid].append({\"N\":N, \"dfs\":dfs, \"docid\":docid, \"docno\":docno, \"doclen\": doclen, \"avgdl\": avgdl, \"rel\":rel, \"pos\":plists})\n",
    "\n",
    "    return  qid2docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qid2docs = loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Query Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadQidInfo():\n",
    "    qidDict = dict()\n",
    "    for filename in os.listdir(os.curdir):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            e = xml.etree.ElementTree.parse(filename).getroot()\n",
    "            for query in e.findall('topic'):\n",
    "                qidDict[int(query.get(\"number\"))] = tuple([int(query.get(\"number\")), query.get(\"type\"), query[0].text])\n",
    "    return qidDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qidInfo = loadQidInfo()\n",
    "#print len(qidInfo)\n",
    "#print qidInfo[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build OCCURENCE Probability MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildScores(qid2docs):\n",
    "    for qid in qid2docs:\n",
    "        print qid\n",
    "        qid2scores=defaultdict(list)\n",
    "        docs=qid2docs[qid]\n",
    "        for d in docs:\n",
    "            p2t={}\n",
    "            for idx in range(0, len(d[\"pos\"])):\n",
    "                for p in d[\"pos\"][idx]:\n",
    "                    p2t[p]=idx\n",
    "            N = d[\"N\"]\n",
    "            dfs = d[\"dfs\"]\n",
    "            tfs = np.zeros((len(d[\"pos\"]),), dtype=np.int)\n",
    "            doclen=d[\"doclen\"]\n",
    "            avg_doclen = d[\"avgdl\"]\n",
    "            scores = np.zeros((doclen,), dtype=np.float)\n",
    "            for pos in range(0, doclen):\n",
    "                if pos in p2t:\n",
    "                    t = p2t[pos]\n",
    "                    tfs[t]+=1\n",
    "                score=0\n",
    "                for idx in range(0, len(tfs)):\n",
    "                    score+=bm25(tfs[idx], dfs[idx], pos+1, N, avg_doclen)\n",
    "                scores[pos]=score\n",
    "            docid=d[\"docid\"]\n",
    "            docno=d[\"docno\"]\n",
    "            rel=d[\"rel\"]\n",
    "            qid2scores[qid].append({\"rel\": rel,  \"docid\": docid, \"docno\": docno, \"scores\":scores})\n",
    "    return qid2scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-44804e57fd06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqid2scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildScores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqid2docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-162e650d375c>\u001b[0m in \u001b[0;36mbuildScores\u001b[0;34m(qid2docs)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0mscore\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mbm25\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_doclen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdocid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"docid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-cbcabcbbb3a4>\u001b[0m in \u001b[0;36mbm25\u001b[0;34m(tf, df, doclen, N, avg_doclen, k1, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoclen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_doclen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdoclen\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mavg_doclen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "qid2scores = buildScores(qid2docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qid_RelevantDocsDistribFlat = dict()\n",
    "qid_AllDocsDistribFlat = dict() \n",
    "qid_RelevantDocsDistribProx = dict()\n",
    "qid_AllDocsDistribProx = dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at PER QUERY level\n",
    "\n",
    "#### RELEVANT\n",
    "for qid, relDocidList in qid2reldoc.iteritems():\n",
    "    flatlists = [docid2flatlist[qid, docid] for docid in relDocidList]\n",
    "    p = buildProbability(flatlists)\n",
    "    qid_RelevantDocsDistribFlat[qid] = p\n",
    "    proxlists = [docid2proxlist[qid, docid] for docid in relDocidList]\n",
    "    p = buildProbability(proxlists)\n",
    "    qid_RelevantDocsDistribProx[qid] = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ALL for that query\n",
    "allflatlists={}\n",
    "allproxlists={}\n",
    "for qid, docid in docid2flatlist:\n",
    "    if qid not in allflatlists:\n",
    "        allflatlists[qid]=[]\n",
    "    allflatlists[qid].append(docid2flatlist[qid, docid])\n",
    "for qid, docid in docid2proxlist:\n",
    "    if qid not in allproxlists:\n",
    "        allproxlists[qid]=[]\n",
    "    allproxlists[qid].append(docid2proxlist[qid, docid])    \n",
    "    \n",
    "for qid in allflatlists:\n",
    "    p = buildProbability(allflatlists[qid])\n",
    "    qid_AllDocsDistribFlat[qid] = p\n",
    "        \n",
    "for qid in allproxlists:\n",
    "    p = buildProbability(allproxlists[qid])\n",
    "    qid_AllDocsDistribProx[qid] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KL divergence\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html\n",
    "\n",
    "scipy.stats.entropy(pk, qk=None, base=None)\n",
    "\n",
    "Calculate the entropy of a distribution for given probability values.\n",
    "If only probabilities pk are given, the entropy is calculated as S = -sum(pk * log(pk), axis=0).\n",
    "If qk is not None, then compute the Kullback-Leibler divergence S = sum(pk * log(pk / qk), axis=0).\n",
    "\n",
    "This routine will normalize pk and qk if they donâ€™t sum to 1.\n",
    "\n",
    "Parameters:\t\n",
    "\n",
    "    pk : sequence\n",
    "       Defines the (discrete) distribution. pk[i] is the (possibly unnormalized) probability of event i.\n",
    "       \n",
    "    qk : sequence, optional\n",
    "        Sequence against which the relative entropy is computed. Should be in the same format as pk.\n",
    "        \n",
    "    base : float, optional\n",
    "        The logarithmic base to use, defaults to e (natural logarithm).\n",
    "Returns:\t\n",
    "\n",
    "    S : float\n",
    "    The calculated entropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "kl_Rel_All_Flat = dict()\n",
    "kl_Rel_All_Prox = dict()\n",
    "for qid in qid_RelevantDocsDistribFlat.keys():\n",
    "    kl_Rel_All_Flat[qid] = stats.entropy(qid_RelevantDocsDistribFlat[qid], qid_AllDocsDistribFlat[qid])\n",
    "for qid in qid_RelevantDocsDistribProx.keys():\n",
    "    kl_Rel_All_Prox[qid] = stats.entropy(qid_RelevantDocsDistribProx[qid], qid_AllDocsDistribProx[qid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for qid in qidInfo:\n",
    "    \n",
    "    plt.figure(figsize=(16, 3))\n",
    "    \n",
    "    plt.subplot(1,4,1)\n",
    "    if qid in qid_RelevantDocsDistribFlat:\n",
    "        a = qid_RelevantDocsDistribFlat[qid].reshape((40, 50))\n",
    "        plt.imshow(a, cmap='hot')\n",
    "\n",
    "    plt.subplot(1,4,2)\n",
    "    if qid in qid_AllDocsDistribFlat:\n",
    "        a = qid_AllDocsDistribFlat[qid].reshape((40, 50))\n",
    "        plt.imshow(a, cmap='hot')\n",
    "    \n",
    "    plt.subplot(1,4,3)\n",
    "    if qid in qid_RelevantDocsDistribProx:\n",
    "        a = qid_RelevantDocsDistribProx[qid].reshape((40, 50))    \n",
    "        plt.imshow(a, cmap='hot')\n",
    "\n",
    "    plt.subplot(1,4,4)\n",
    "    if qid in qid_AllDocsDistribProx:\n",
    "        a = qid_AllDocsDistribProx[qid].reshape((40, 50))\n",
    "        plt.imshow(a, cmap='hot')\n",
    "\n",
    "    if qid in kl_Rel_All_Flat and qid in kl_Rel_All_Prox:\n",
    "        plt.suptitle(str(qidInfo[qid])+ \" \" + str(kl_Rel_All_Flat[qid]) + \" \" + str(kl_Rel_All_Prox[qid]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at PER QUERY level\n",
    "\n",
    "#### RELEVANT\n",
    "global_flat = []\n",
    "for qid, relDocidList in qid2reldoc.iteritems():\n",
    "    global_flat += [docid2flatlist[qid, docid] for docid in relDocidList]\n",
    "RelevantDocsDistribFlat = buildProbability(global_flat)\n",
    "\n",
    "global_prox = []\n",
    "for qid, relDocidList in qid2reldoc.iteritems():\n",
    "    global_prox += [docid2proxlist[qid, docid] for docid in relDocidList]\n",
    "RelevantDocsDistribProx = buildProbability(global_prox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ALL for that query\n",
    "global_flat=[]\n",
    "global_prox=[]\n",
    "for qid, docid in docid2flatlist:\n",
    "    global_flat.append(docid2flatlist[qid, docid])\n",
    "for qid, docid in docid2proxlist:\n",
    "    global_prox.append(docid2proxlist[qid, docid])    \n",
    "    \n",
    "AllDocsDistribFlat = buildProbability(global_flat)\n",
    "AllDocsDistribProx = buildProbability(global_prox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qid2and={}\n",
    "for qid in qidInfo:\n",
    "    for qid2, docid in docid2flatlist:\n",
    "        if qid == qid2:\n",
    "            v = np.zeros(2000)\n",
    "            for x in docid2flatlist[qid, docid]:\n",
    "                if x < 2000:\n",
    "                    v[x] = 1\n",
    "            p = 1.0\n",
    "            for x in range(0, 2000):\n",
    "                if v[x] == 1:\n",
    "                    p *= qid_AllDocsDistribFlat[qid][x]\n",
    "                else:\n",
    "                    p *= 1 - qid_AllDocsDistribFlat[qid][x]\n",
    "            if p == 0:\n",
    "                print(\"%d %d %d\" % (qid, docid, docid in qid2reldoc[qid]))\n",
    "            qid2and[qid, docid] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(qid2and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
