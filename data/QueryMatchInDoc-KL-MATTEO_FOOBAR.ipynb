{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import os\n",
    "import xml.etree.ElementTree\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computePhraseFrequency(plists, window): \n",
    "            \n",
    "    MAX=float(\"+inf\")\n",
    "    MIN=float(\"-inf\")\n",
    "        \n",
    "    results=[]\n",
    "    for l in plists:\n",
    "        if len(l) < 1:\n",
    "            return results\n",
    "    \n",
    "    positions=plists \n",
    "    index = [0] * len(positions)\n",
    "    curr_occ = [0] * len (positions)\n",
    "    max_curr_occ = MIN\n",
    "    \n",
    "    for i in range(0, len(positions)):\n",
    "        curr_occ[i] = positions[i][0]\n",
    "        if curr_occ[i] > max_curr_occ:\n",
    "            max_curr_occ = curr_occ[i]\n",
    "    \n",
    "    lsym=0\n",
    "    rsym=0\n",
    "    lpos=0\n",
    "    while max_curr_occ < MAX:\n",
    "        _max = MIN\n",
    "        _min = MAX\n",
    "        for i in range(0, len(positions)):\n",
    "            if curr_occ[i] > _max:\n",
    "                _max = curr_occ[i]\n",
    "                rsym = i\n",
    "            if curr_occ[i] < _min:\n",
    "                _min = curr_occ[i]\n",
    "                lsym = i\n",
    "                \n",
    "        if index[lsym] == len(positions[lsym]) - 1 :\n",
    "            lpos = MAX\n",
    "        else :\n",
    "            index[lsym]+=1\n",
    "            lpos = positions[lsym][index[lsym]]\n",
    "        \n",
    "        if lpos > curr_occ[rsym] and curr_occ[rsym] - curr_occ[lsym] < window:\n",
    "                results.append(curr_occ[lsym])\n",
    "                \n",
    "        max_curr_occ = MAX\n",
    "        if lpos != MAX :\n",
    "            max_curr_occ = MIN\n",
    "            curr_occ[lsym] = lpos\n",
    "            for i in range(0, len(positions)):\n",
    "                if curr_occ[i] > max_curr_occ:\n",
    "                    max_curr_occ = curr_occ[i]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qid docid docno doclen rel positions\n",
    "def loadData():\n",
    "    qid2reldoc = defaultdict(list)\n",
    "    qid2irrdoc = defaultdict(list)\n",
    "    docid2doclen = defaultdict(int)\n",
    "    docid2flatlist = defaultdict(list)\n",
    "    docid2proxlist = defaultdict(list)\n",
    "\n",
    "    \n",
    "    i = 0 \n",
    "    with open(\"wtall_qrels_pos.clean.txt\") as f:\n",
    "        for l in f:\n",
    "            # split row\n",
    "            fields = l.split(\"\\t\")\n",
    "            \n",
    "            # get the data\n",
    "            qid = int(fields[0])\n",
    "            docid = int(fields[1])\n",
    "            doclen=int(fields[3])\n",
    "            rel=int(fields[4])\n",
    "            plists = ast.literal_eval(fields[5])\n",
    "            if len(plists)==1:\n",
    "                prox_list=plists[0]\n",
    "            else:\n",
    "                prox_list = computePhraseFrequency(plists, 20)\n",
    "            flat_list = [item for sublist in plists for item in sublist]\n",
    "\n",
    "            \n",
    "            # put data in dicts\n",
    "            docid2doclen[docid] = doclen\n",
    "            docid2flatlist[qid, docid] = flat_list\n",
    "            docid2proxlist[qid, docid] = prox_list\n",
    "            if rel > 0:\n",
    "                qid2reldoc[qid].append(docid)\n",
    "            else:\n",
    "                qid2irrdoc[qid].append(docid)\n",
    "\n",
    "    return  qid2reldoc, qid2irrdoc, docid2doclen, docid2flatlist, docid2proxlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qid2reldoc, qid2irrdoc, docid2doclen, docid2flatlist, docid2proxlist = loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stats on document length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadQidInfo():\n",
    "    qidDict = dict()\n",
    "    for filename in os.listdir(os.curdir):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            e = xml.etree.ElementTree.parse(filename).getroot()\n",
    "            for query in e.findall('topic'):\n",
    "                qidDict[int(query.get(\"number\"))] = tuple([int(query.get(\"number\")), query.get(\"type\"), query[0].text])\n",
    "    return qidDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qidInfo = loadQidInfo()\n",
    "print len(qidInfo)\n",
    "print qidInfo[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL DOCs with RELEVANCE\n",
    "def plotStats(docid2doclen):\n",
    "    sorted_per_freq = Counter(docid2doclen.values()).most_common()\n",
    "    sorted_per_length = sorted(sorted_per_freq, key=lambda i: i[0])\n",
    "    doc_len, doc_len_freq = zip(*sorted_per_length)\n",
    "    plt.loglog(doc_len, doc_len_freq, 'r.')\n",
    "    plt.xlabel(\"DocLen\")\n",
    "    plt.ylabel(\"Freq\")\n",
    "    \n",
    "    \n",
    "plotStats(docid2doclen)\n",
    "stats.describe(docid2doclen.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RELEVANT DOCS\n",
    "relevantdocs = [item for sublist in qid2reldoc.values() for item in sublist]\n",
    "print len(relevantdocs)\n",
    "print Counter(relevantdocs).most_common(20)\n",
    "relevant_doclen_dict = {docid:docid2doclen[docid] for docid in relevantdocs}\n",
    "\n",
    "print \"---------------------------\"\n",
    "print \"Num Relevant Docs (unique): \", len(relevant_doclen_dict)\n",
    "print \"Stats: \",stats.describe(relevant_doclen_dict.values())\n",
    "print \"Median: \", np.median(relevant_doclen_dict.values())\n",
    "plotStats(relevant_doclen_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build OCCURENCE Probability MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildProbability(flatlists, max_doc_len=2000):\n",
    "    probability = np.zeros(max_doc_len)\n",
    "    probability.fill(np.inf)\n",
    "    occurence_ndarray = np.zeros(max_doc_len)\n",
    "    for fl in flatlists:\n",
    "        filtered_flatlist = [x for x in fl if x < max_doc_len]\n",
    "        occurence_ndarray[filtered_flatlist] += 1\n",
    "    if len(flatlists) > 0:\n",
    "        probability = occurence_ndarray / len(flatlists)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qid_RelevantDocsDistribFlat = dict()\n",
    "qid_AllDocsDistribFlat = dict() \n",
    "qid_RelevantDocsDistribProx = dict()\n",
    "qid_AllDocsDistribProx = dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at PER QUERY level\n",
    "\n",
    "#### RELEVANT\n",
    "for qid, relDocidList in qid2reldoc.iteritems():\n",
    "    flatlists = [docid2flatlist[qid, docid] for docid in relDocidList]\n",
    "    p = buildProbability(flatlists)\n",
    "    qid_RelevantDocsDistribFlat[qid] = p\n",
    "    proxlists = [docid2proxlist[qid, docid] for docid in relDocidList]\n",
    "    p = buildProbability(proxlists)\n",
    "    qid_RelevantDocsDistribProx[qid] = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ALL for that query\n",
    "allflatlists={}\n",
    "allproxlists={}\n",
    "for qid, docid in docid2flatlist:\n",
    "    if qid not in allflatlists:\n",
    "        allflatlists[qid]=[]\n",
    "    allflatlists[qid].append(docid2flatlist[qid, docid])\n",
    "for qid, docid in docid2proxlist:\n",
    "    if qid not in allproxlists:\n",
    "        allproxlists[qid]=[]\n",
    "    allproxlists[qid].append(docid2proxlist[qid, docid])    \n",
    "    \n",
    "for qid in allflatlists:\n",
    "    p = buildProbability(allflatlists[qid])\n",
    "    qid_AllDocsDistribFlat[qid] = p\n",
    "        \n",
    "for qid in allproxlists:\n",
    "    p = buildProbability(allproxlists[qid])\n",
    "    qid_AllDocsDistribProx[qid] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KL divergence\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html\n",
    "\n",
    "scipy.stats.entropy(pk, qk=None, base=None)\n",
    "\n",
    "Calculate the entropy of a distribution for given probability values.\n",
    "If only probabilities pk are given, the entropy is calculated as S = -sum(pk * log(pk), axis=0).\n",
    "If qk is not None, then compute the Kullback-Leibler divergence S = sum(pk * log(pk / qk), axis=0).\n",
    "\n",
    "This routine will normalize pk and qk if they don’t sum to 1.\n",
    "\n",
    "Parameters:\t\n",
    "\n",
    "    pk : sequence\n",
    "       Defines the (discrete) distribution. pk[i] is the (possibly unnormalized) probability of event i.\n",
    "       \n",
    "    qk : sequence, optional\n",
    "        Sequence against which the relative entropy is computed. Should be in the same format as pk.\n",
    "        \n",
    "    base : float, optional\n",
    "        The logarithmic base to use, defaults to e (natural logarithm).\n",
    "Returns:\t\n",
    "\n",
    "    S : float\n",
    "    The calculated entropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "kl_Rel_All_Flat = dict()\n",
    "kl_Rel_All_Prox = dict()\n",
    "for qid in qid_RelevantDocsDistribFlat.keys():\n",
    "    kl_Rel_All_Flat[qid] = stats.entropy(qid_RelevantDocsDistribFlat[qid], qid_AllDocsDistribFlat[qid])\n",
    "for qid in qid_RelevantDocsDistribProx.keys():\n",
    "    kl_Rel_All_Prox[qid] = stats.entropy(qid_RelevantDocsDistribProx[qid], qid_AllDocsDistribProx[qid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for qid in qidInfo:\n",
    "    \n",
    "    plt.figure(figsize=(16, 3))\n",
    "    \n",
    "    plt.subplot(1,4,1)\n",
    "    if qid in qid_RelevantDocsDistribFlat:\n",
    "        a = qid_RelevantDocsDistribFlat[qid].reshape((40, 50))\n",
    "        plt.imshow(a, cmap='hot')\n",
    "\n",
    "    plt.subplot(1,4,2)\n",
    "    if qid in qid_AllDocsDistribFlat:\n",
    "        a = qid_AllDocsDistribFlat[qid].reshape((40, 50))\n",
    "        plt.imshow(a, cmap='hot')\n",
    "    \n",
    "    plt.subplot(1,4,3)\n",
    "    if qid in qid_RelevantDocsDistribProx:\n",
    "        a = qid_RelevantDocsDistribProx[qid].reshape((40, 50))    \n",
    "        plt.imshow(a, cmap='hot')\n",
    "\n",
    "    plt.subplot(1,4,4)\n",
    "    if qid in qid_AllDocsDistribProx:\n",
    "        a = qid_AllDocsDistribProx[qid].reshape((40, 50))\n",
    "        plt.imshow(a, cmap='hot')\n",
    "\n",
    "    if qid in kl_Rel_All_Flat and qid in kl_Rel_All_Prox:\n",
    "        plt.suptitle(str(qidInfo[qid])+ \" \" + str(kl_Rel_All_Flat[qid]) + \" \" + str(kl_Rel_All_Prox[qid]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# at PER QUERY level\n",
    "\n",
    "#### RELEVANT\n",
    "global_flat = []\n",
    "for qid, relDocidList in qid2reldoc.iteritems():\n",
    "    global_flat += [docid2flatlist[qid, docid] for docid in relDocidList]\n",
    "RelevantDocsDistribFlat = buildProbability(global_flat)\n",
    "\n",
    "global_prox = []\n",
    "for qid, relDocidList in qid2reldoc.iteritems():\n",
    "    global_prox += [docid2proxlist[qid, docid] for docid in relDocidList]\n",
    "RelevantDocsDistribProx = buildProbability(global_prox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ALL for that query\n",
    "global_flat=[]\n",
    "global_prox=[]\n",
    "for qid, docid in docid2flatlist:\n",
    "    global_flat.append(docid2flatlist[qid, docid])\n",
    "for qid, docid in docid2proxlist:\n",
    "    global_prox.append(docid2proxlist[qid, docid])    \n",
    "    \n",
    "AllDocsDistribFlat = buildProbability(global_flat)\n",
    "AllDocsDistribProx = buildProbability(global_prox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid2and={}\n",
    "for qid in qidInfo:\n",
    "    for qid2, docid in docid2flatlist:\n",
    "        if qid == qid2:\n",
    "            v = np.zeros(2000)\n",
    "            for x in docid2flatlist[qid, docid]:\n",
    "                if x < 2000:\n",
    "                    v[x] = 1\n",
    "            p = 1.0\n",
    "            for x in range(0, 2000):\n",
    "                if v[x] == 1:\n",
    "                    p *= qid_AllDocsDistribFlat[qid][x]\n",
    "                else:\n",
    "                    p *= 1 - qid_AllDocsDistribFlat[qid][x]\n",
    "            if p == 0:\n",
    "                print(\"%d %d %d\" % (qid, docid, docid in qid2reldoc[qid]))\n",
    "            qid2and[qid, docid] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(qid2and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
